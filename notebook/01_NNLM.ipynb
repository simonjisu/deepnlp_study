{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Neural Probabilistic Language Model\n",
    "---\n",
    "Paper implementation: \n",
    "\n",
    "* paper: [A Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf) - Yoshua Bengio, 2003\n",
    "* [blog](https://simonjisu.github.io/nlp/2018/08/22/neuralnetworklm.html)\n",
    "* [slide share](http://bit.ly/2OkYFkY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. Preprocessing\n",
    "2. Model\n",
    "3. Result: \n",
    "    * Perplexity\n",
    "    * Similarity versus \"gensim Word2Vec\"\n",
    "    * Training Time\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]+['paper_code', 'NNLM']))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from nnlm_data_loader import DataSet\n",
    "from model import NNLM\n",
    "from konlpy.tag import Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = \"cuda\" if USE_CUDA else None\n",
    "BATCH = 1024\n",
    "N_GRAM = 5\n",
    "TAGGER = lambda x: ['/'.join(y) for y in Twitter().pos(x, norm=True)]\n",
    "vocab_path = '../paper_code/NNLM/model/vocabulary' # to fix vocabulary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, _, _ = DataSet(base_path='../data/nsmc/', train='train.txt', valid='valid.txt', test='test.txt', \n",
    "#             n_gram=N_GRAM, tokenizer=TAGGER, save_tokens=True, direct_load=False, remove_short=True).splits()\n",
    "# train_data.vocab.save(vocab_path, train_data.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_creator = DataSet(base_path='../data/nsmc/', \n",
    "                          train='train_tokens', valid='valid_tokens', test='test_tokens',\n",
    "                          n_gram=N_GRAM, tokenizer=str.split, save_tokens=False, \n",
    "                          direct_load=True, remove_short=True, device=DEVICE,\n",
    "                          fixed_vocab=vocab_path)\n",
    "train_data, valid_data, test_data = dataset_creator.splits()\n",
    "train_loader, valid_loader, test_loader = dataset_creator.create_loader(train=train_data, valid=valid_data, test=test_data,\n",
    "                                                                        batch_size=BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2167155, 124660)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking removed short sentences which length of tokens is lower then N_GRAM(=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180000, 17727)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual used, number of train sentences: 162273\n",
    "train_data._total, train_data._removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 968)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual used, number of valid sentences: 9032\n",
    "valid_data._total, valid_data._removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is 63202\n"
     ]
    }
   ],
   "source": [
    "# 16383 words : 30 ~~ 63202: 100\n",
    "V = len(train_data.vocab)\n",
    "E = 100\n",
    "H = 500\n",
    "LR = 0.001\n",
    "WD = 0.00001\n",
    "STEP = 10\n",
    "print(\"vocab size is\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnlm = NNLM(embed_size=E, hidden_size=H, vocab_size=V, num_prev_tokens=(N_GRAM-1))\n",
    "if USE_CUDA:\n",
    "    nnlm = nnlm.cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(nnlm.parameters(), lr=LR, weight_decay=WD)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(gamma=0.1, milestones=[5], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(x):\n",
    "    return -torch.log(x).sum() / x.size(0)\n",
    "\n",
    "def validation(model, loader):\n",
    "    model.eval()\n",
    "    pp = 0\n",
    "    acc = 0\n",
    "    for batch in loader:\n",
    "        inputs, targets = batch[0], batch[1]\n",
    "        preds = model.predict(inputs)\n",
    "        probs, idxes = preds.max(1)\n",
    "        acc += torch.eq(idxes, targets).sum().item()\n",
    "        pp += perplexity(probs).item()\n",
    "        \n",
    "    return acc, pp/len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10][0/2117] train_loss: 11.0958\n",
      "[1/10][1000/2117] train_loss: 6.5791\n",
      "[1/10][2000/2117] train_loss: 6.2977\n",
      "==============================\n",
      "[1/10]\n",
      " valid_perplextiy: 2.1833 \n",
      " valid_accuracy: 0.1735\n",
      "==============================\n",
      "[2/10][0/2117] train_loss: 5.8066\n",
      "[2/10][1000/2117] train_loss: 5.3531\n",
      "[2/10][2000/2117] train_loss: 5.3857\n",
      "==============================\n",
      "[2/10]\n",
      " valid_perplextiy: 2.0390 \n",
      " valid_accuracy: 0.1914\n",
      "==============================\n",
      "[3/10][0/2117] train_loss: 5.3604\n",
      "[3/10][1000/2117] train_loss: 5.0198\n",
      "[3/10][2000/2117] train_loss: 5.0861\n",
      "==============================\n",
      "[3/10]\n",
      " valid_perplextiy: 1.9718 \n",
      " valid_accuracy: 0.1983\n",
      "==============================\n",
      "[4/10][0/2117] train_loss: 5.1429\n",
      "[4/10][1000/2117] train_loss: 4.8299\n",
      "[4/10][2000/2117] train_loss: 4.9050\n",
      "==============================\n",
      "[4/10]\n",
      " valid_perplextiy: 1.9294 \n",
      " valid_accuracy: 0.2015\n",
      "==============================\n",
      "[5/10][0/2117] train_loss: 5.0019\n",
      "[5/10][1000/2117] train_loss: 4.6956\n",
      "[5/10][2000/2117] train_loss: 4.7740\n",
      "==============================\n",
      "[5/10]\n",
      " valid_perplextiy: 1.8975 \n",
      " valid_accuracy: 0.2036\n",
      "==============================\n",
      "[6/10][0/2117] train_loss: 4.8963\n",
      "[6/10][1000/2117] train_loss: 4.5474\n",
      "[6/10][2000/2117] train_loss: 4.4194\n",
      "==============================\n",
      "[6/10]\n",
      " valid_perplextiy: 1.9439 \n",
      " valid_accuracy: 0.2112\n",
      "==============================\n",
      "[7/10][0/2117] train_loss: 4.6757\n",
      "[7/10][1000/2117] train_loss: 4.4229\n",
      "[7/10][2000/2117] train_loss: 4.3498\n",
      "==============================\n",
      "[7/10]\n",
      " valid_perplextiy: 1.9402 \n",
      " valid_accuracy: 0.2114\n",
      "==============================\n",
      "[8/10][0/2117] train_loss: 4.6002\n",
      "[8/10][1000/2117] train_loss: 4.3649\n",
      "[8/10][2000/2117] train_loss: 4.3170\n",
      "==============================\n",
      "[8/10]\n",
      " valid_perplextiy: 1.9358 \n",
      " valid_accuracy: 0.2117\n",
      "==============================\n",
      "[9/10][0/2117] train_loss: 4.5468\n",
      "[9/10][1000/2117] train_loss: 4.3232\n",
      "[9/10][2000/2117] train_loss: 4.2926\n",
      "==============================\n",
      "[9/10]\n",
      " valid_perplextiy: 1.9314 \n",
      " valid_accuracy: 0.2118\n",
      "==============================\n",
      "[10/10][0/2117] train_loss: 4.5037\n",
      "[10/10][1000/2117] train_loss: 4.2895\n",
      "[10/10][2000/2117] train_loss: 4.2720\n",
      "==============================\n",
      "[10/10]\n",
      " valid_perplextiy: 1.9272 \n",
      " valid_accuracy: 0.2117\n",
      "==============================\n",
      "Training Excution time with validation: 34 m 51.8087 s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for step in range(STEP):\n",
    "    nnlm.train()\n",
    "    scheduler.step()\n",
    "    losses=[]\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        inputs, targets = batch[0], batch[1]\n",
    "\n",
    "        nnlm.zero_grad()\n",
    "\n",
    "        outputs = nnlm(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, targets.view(-1))\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(nnlm.parameters(), 50.0)  # gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            msg = '[{}/{}][{}/{}] train_loss: {:.4f}'.format(step+1, STEP, i, len(train_loader), np.mean(losses))\n",
    "            print(msg)\n",
    "            \n",
    "    acc_valid, pp_valid = validation(model=nnlm, loader=valid_loader)\n",
    "    print('='*30)\n",
    "    msg = '[{}/{}]\\n valid_perplextiy: {:.4f} \\n valid_accuracy: {:.4f}'.format(step+1, STEP, pp_valid, acc_valid/len(valid_data))\n",
    "    print(msg)\n",
    "    print('='*30)\n",
    "    \n",
    "end_time = time.time()\n",
    "minute = int((end_time-start_time) // 60)\n",
    "print('Training Excution time with validation: {:d} m {:.4f} s'.format(minute, (end_time-start_time)-minute*60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nnlm.state_dict(), '../paper_code/NNLM/model/nnlm.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnlm.load_state_dict(torch.load('../paper_code/NNLM/model/nnlm.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_perplextiy: 1.9268, test_accuracy: 0.2118\n"
     ]
    }
   ],
   "source": [
    "acc, pp = validation(model=nnlm, loader=test_loader)\n",
    "msg = 'test_perplextiy: {:.4f}, test_accuracy: {:.4f}'.format(pp, acc/len(test_data))\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent = '요즘 나오는 어린이 영화보다 수준 낮은 시나리오 거기다 우리가 아는 윌스미스 보다 어린 윌스미스에 발연기는 보너스'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_sample(test_sent, model, dataset):\n",
    "    test_sent_tokens = TAGGER(dataset_creator._preprocessing(test_sent))\n",
    "    test_sent_ngrams = dataset.get_ngrams([test_sent_tokens])\n",
    "    datas = np.array(dataset.numerical(test_sent_ngrams))\n",
    "    \n",
    "    x = torch.LongTensor(datas[:, :-1])\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        model = model.cpu()\n",
    "    \n",
    "    for tkns, inputs in zip(test_sent_ngrams, x):\n",
    "        pred = model.predict(inputs.view(1, -1)).max(1)[1]\n",
    "        print(' '.join(tkns[:-1]), '-->', dataset.vocab.itos[pred.item()], '\\t| target:', tkns[-1])\n",
    "        \n",
    "    print('='*50)\n",
    "    print('given {} words: {}'.format(dataset.n_gram-1, ' '.join(test_sent_ngrams[0][:-1])))\n",
    "    print('-'*50)\n",
    "    preds = test_sent_ngrams[0][:-1]\n",
    "    sent_length = len(test_sent_tokens)\n",
    "    i = 0\n",
    "    inputs = dataset.numerical([test_sent_ngrams[0][:-1]])[0]\n",
    "    while i <= sent_length:\n",
    "        pred = model.predict(torch.LongTensor(inputs).view(1, -1)).max(1)[1].item()\n",
    "        preds.append(dataset.vocab.itos[pred])\n",
    "        inputs.pop(0)\n",
    "        inputs.append(pred)\n",
    "        i += 1\n",
    "    \n",
    "    print(' '.join([x.split('/')[0] for x in preds]))\n",
    "    string = ' '.join(preds)\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요즘/Noun 나오는/Verb 어린이/Noun 영화/Noun --> 가/Josa \t| target: 보다/Josa\n",
      "나오는/Verb 어린이/Noun 영화/Noun 보다/Josa --> 더/Noun \t| target: 수준/Noun\n",
      "어린이/Noun 영화/Noun 보다/Josa 수준/Noun --> 이/Josa \t| target: 낮은/Adjective\n",
      "영화/Noun 보다/Josa 수준/Noun 낮은/Adjective --> 영화/Noun \t| target: 시나리오/Noun\n",
      "보다/Josa 수준/Noun 낮은/Adjective 시나리오/Noun --> 가/Josa \t| target: 거기/Noun\n",
      "수준/Noun 낮은/Adjective 시나리오/Noun 거기/Noun --> 에/Josa \t| target: 다/Josa\n",
      "낮은/Adjective 시나리오/Noun 거기/Noun 다/Josa --> ./Punctuation \t| target: 우리/Noun\n",
      "시나리오/Noun 거기/Noun 다/Josa 우리/Noun --> 는/Josa \t| target: 가/Josa\n",
      "거기/Noun 다/Josa 우리/Noun 가/Josa --> 뭐/Noun \t| target: 아는/Verb\n",
      "다/Josa 우리/Noun 가/Josa 아는/Verb --> 사람/Noun \t| target: 윌스미스/Noun\n",
      "우리/Noun 가/Josa 아는/Verb 윌스미스/Noun --> 인데/Josa \t| target: 보다/Verb\n",
      "가/Josa 아는/Verb 윌스미스/Noun 보다/Verb --> 가/Eomi \t| target: 어린/Verb\n",
      "아는/Verb 윌스미스/Noun 보다/Verb 어린/Verb --> 애/Noun \t| target: 윌스미스/Noun\n",
      "윌스미스/Noun 보다/Verb 어린/Verb 윌스미스/Noun --> 가/Josa \t| target: 에/Josa\n",
      "보다/Verb 어린/Verb 윌스미스/Noun 에/Josa --> 대한/Noun \t| target: 발연기/Noun\n",
      "어린/Verb 윌스미스/Noun 에/Josa 발연기/Noun --> 에/Josa \t| target: 는/Josa\n",
      "윌스미스/Noun 에/Josa 발연기/Noun 는/Josa --> 좋/Adjective \t| target: 보너스/Noun\n",
      "==================================================\n",
      "given 4 words: 요즘/Noun 나오는/Verb 어린이/Noun 영화/Noun\n",
      "--------------------------------------------------\n",
      "요즘 나오는 어린이 영화 가 다 있 나 ? ᄏ 아 놔 서 봤 는데 이 것 은 뭐 . ᄏ ; 이 것 은 뭐\n"
     ]
    }
   ],
   "source": [
    "lm_string = predict_test_sample(test_sent, nnlm, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'요즘/Noun 나오는/Verb 어린이/Noun 영화/Noun 가/Josa 다/Adverb 있/Adjective 나/Eomi ?/Punctuation ᄏ/Foreign 아/Exclamation 놔/Verb 서/Eomi 봤/Verb 는데/Eomi 이/Determiner 것/Noun 은/Josa 뭐/Noun ./Punctuation ᄏ/Foreign ;/Punctuation 이/Determiner 것/Noun 은/Josa 뭐/Noun'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
