{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiDAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQuAD: https://rajpurkar.github.io/SQuAD-explorer/\n",
    "* BiDAF Paper: https://arxiv.org/abs/1611.01603 \n",
    "* Score: \n",
    "    - BiDAF++: EM) 77.573, F1) 84.858\n",
    "    - BiDAF: EM) 67.974, F1) 77.323"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data EDA: SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**squad-json**\n",
    "\n",
    "* version\n",
    "* data: 442\n",
    "    * title: (str)\n",
    "    * paragraphs: (m, list(dict))\n",
    "        * context: (n, str)\n",
    "        * qas: (k, dict)\n",
    "            * answers: (list(dict))\n",
    "                * answer_start: (int)\n",
    "                * text: (str)\n",
    "            * question: (str)\n",
    "            * id: (str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of data: 442\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "squad_data = json.load(open('../data/SQuAD/squad/train-v1.1.json'))\n",
    "print('lenght of data: {}'.format(len(squad_data['data'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ex(data, data_idx):\n",
    "    ex = data[data_idx]\n",
    "    # select idxes\n",
    "    pa_idx = int(input('insert paragraph idx (total: {}):'.format(len(ex['paragraphs']))))\n",
    "    assert (pa_idx >= 1) & (pa_idx <= len(ex['paragraphs'])), 'error'\n",
    "    pa_idx -= 1\n",
    "    ex_pa = ex['paragraphs'][pa_idx]\n",
    "    qa_idx = int(input('insert qa idx (total: {}):'.format(len(ex_pa['qas']))))\n",
    "    assert (qa_idx >= 1) & (qa_idx <= len(ex_pa['qas'])), 'error'\n",
    "    qa_idx -= 1\n",
    "    # hightlight\n",
    "    qas = ex_pa['qas'][qa_idx]\n",
    "    highlight_idxes = [(x['answer_start'], \n",
    "                        x['answer_start']+len(x['text']),\n",
    "                        x['text']) for x in qas['answers']]\n",
    "    highlight_context = ex_pa['context']\n",
    "    for (*_, t) in highlight_idxes:\n",
    "        temp = highlight_context.split(t)\n",
    "        temp.insert(1, '\\033[40;33m'+t+'\\033[m')\n",
    "        highlight_context = ''.join(temp)\n",
    "    print('-'*20)\n",
    "    print('Title: {}'.format(ex['title']))\n",
    "    print('-'*20)\n",
    "    print('paragraph({}) context:'.format(pa_idx+1))\n",
    "    print('{}'.format(highlight_context))\n",
    "    print('-'*20)\n",
    "    print('1st qa:')\n",
    "    print('question: {}'.format(qas['question']))\n",
    "    for i, ans in enumerate(qas['answers']):\n",
    "        print('answers: {}'.format(ans['text']))\n",
    "        print('answers start {} , end {}'.format(highlight_idxes[i][0], highlight_idxes[i][1]))\n",
    "    return highlight_idxes  # (start_idx, end_idx, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert paragraph idx (total: 66):1\n",
      "insert qa idx (total: 20):1\n",
      "--------------------\n",
      "Title: Beyoncé\n",
      "--------------------\n",
      "paragraph(1) context:\n",
      "Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame \u001b[40;33min the late 1990s\u001b[m as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyoncé's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".\n",
      "--------------------\n",
      "1st qa:\n",
      "question: When did Beyonce start becoming popular?\n",
      "answers: in the late 1990s\n",
      "answers start 269 , end 286\n"
     ]
    }
   ],
   "source": [
    "highlight_idxes = show_ex(squad_data['data'], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected data form\n",
    "\n",
    "**inputs**\n",
    "\n",
    "* context: $[x_1, x_2, \\cdots, x_T ]$\n",
    "* question: $[q_1, q_2, \\cdots, q_J]$\n",
    "\n",
    "**outputs**\n",
    "\n",
    "* start idx, end idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import torch\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "def word_tokenize(tokens):\n",
    "    return [token.replace(\"''\", '\"').replace(\"``\", '\"') for token in nltk.word_tokenize(tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW = data.RawField()\n",
    "CHAR_NESTING = data.Field(batch_first=True, tokenize=list, lower=True)\n",
    "CHAR = data.NestedField(CHAR_NESTING, tokenize=word_tokenize)\n",
    "WORD = data.Field(batch_first=True, tokenize=word_tokenize, lower=True, include_lengths=True)\n",
    "LABEL = data.Field(sequential=False, unk_token=None, use_vocab=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(path):\n",
    "    dump = []\n",
    "    abnormals = [' ', '\\n', '\\u3000', '\\u202f', '\\u2009']\n",
    "\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        data = data['data']\n",
    "\n",
    "        for article in data:\n",
    "            for paragraph in article['paragraphs']:\n",
    "                context = paragraph['context']\n",
    "                tokens = word_tokenize(context)\n",
    "                for qa in paragraph['qas']:\n",
    "                    id = qa['id']\n",
    "                    question = qa['question']\n",
    "                    for ans in qa['answers']:\n",
    "                        answer = ans['text']\n",
    "                        s_idx = ans['answer_start']\n",
    "                        e_idx = s_idx + len(answer)\n",
    "\n",
    "                        l = 0\n",
    "                        s_found = False\n",
    "                        for i, t in enumerate(tokens):\n",
    "                            while l < len(context):\n",
    "                                if context[l] in abnormals:\n",
    "                                    l += 1\n",
    "                                else:\n",
    "                                    break\n",
    "                            # exceptional cases\n",
    "                            if t[0] == '\"' and context[l:l + 2] == '\\'\\'':\n",
    "                                t = '\\'\\'' + t[1:]\n",
    "                            elif t == '\"' and context[l:l + 2] == '\\'\\'':\n",
    "                                t = '\\'\\''\n",
    "\n",
    "                            l += len(t)\n",
    "                            if l > s_idx and s_found == False:\n",
    "                                s_idx = i\n",
    "                                s_found = True\n",
    "                            if l >= e_idx:\n",
    "                                e_idx = i\n",
    "                                break\n",
    "\n",
    "                        dump.append(dict([('id', id),\n",
    "                                          ('context', context),\n",
    "                                          ('question', question),\n",
    "                                          ('answer', answer),\n",
    "                                          ('s_idx', s_idx),\n",
    "                                          ('e_idx', e_idx)]))\n",
    "    \n",
    "    filename = 'prepro_' + path.split('/')[-1]\n",
    "    path = os.path.join(os.path.split(path)[0], filename)\n",
    "    with open(f'{path}', 'w', encoding='utf-8') as f:\n",
    "            for line in dump:\n",
    "                json.dump(line, f)\n",
    "                print('', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/SQuAD/squad/train-v1.1.json'\n",
    "path2 = '../data/SQuAD/squad/dev-v1.1.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_file(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_fields = {'id': ('id', RAW),\n",
    "               's_idx': ('s_idx', LABEL),\n",
    "               'e_idx': ('e_idx', LABEL),\n",
    "               'context': [('c_word', WORD), ('c_char', CHAR)],\n",
    "               'question': [('q_word', WORD), ('q_char', CHAR)]}\n",
    "\n",
    "list_fields = [('id', RAW), ('s_idx', LABEL), ('e_idx', LABEL),\n",
    "               ('c_word', WORD), ('c_char', CHAR),\n",
    "               ('q_word', WORD), ('q_char', CHAR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = data.TabularDataset.splits(\n",
    "                path='../data/SQuAD/squad/',\n",
    "                train='prepro_train-v1.1.json',\n",
    "                validation='prepro_dev-v1.1.json',\n",
    "                format='json',\n",
    "                fields=dict_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train.examples[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention flow Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "vocab_size = 30\n",
    "B = 1\n",
    "T = 3\n",
    "J = 2\n",
    "d = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (B, T, J, 2*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = torch.randn(B, T, 2*d)\n",
    "U = torch.randn(B, J, 2*d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.unsqueeze(2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 2, 10]), torch.Size([1, 3, 2, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_ex = H.unsqueeze(2).expand(shape)\n",
    "U_ex = U.unsqueeze(1).expand(shape)\n",
    "H_ex.size(), U_ex.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_cat = torch.cat([H_ex, U_ex, H_ex * U_ex], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "WS = nn.Linear(6*d, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1604, -0.4624],\n",
       "         [ 0.6376,  0.2100],\n",
       "         [-0.1872, -0.3641]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = WS(w_cat).squeeze(-1)\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### context2query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5749, 0.4251],\n",
       "         [0.6053, 0.3947],\n",
       "         [0.5441, 0.4559]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_soft = S.softmax(2)\n",
    "S_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 10]), torch.Size([1, 3, 2]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.size(), S_soft.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.6446,  0.7566,  0.0930,  0.2170, -0.5246, -0.3520, -0.7119,\n",
       "            0.2180, -0.5943, -0.3211],\n",
       "          [-0.6382,  0.6575,  0.1115,  0.1388, -0.5668, -0.3541, -0.6949,\n",
       "            0.2342, -0.5836, -0.3690],\n",
       "          [-0.6511,  0.8572,  0.0742,  0.2963, -0.4818, -0.3499, -0.7291,\n",
       "            0.2015, -0.6052, -0.2724]]], grad_fn=<BmmBackward>),\n",
       " torch.Size([1, 3, 10]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2q = torch.bmm(S_soft, U)\n",
    "c2q, c2q.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query2context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1604,  0.6376, -0.1872]], grad_fn=<MaxBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_max = S.max(2)[0]  # B, T\n",
    "S_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2384, 0.5295, 0.2321]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = S_max.softmax(1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 10]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.size(), b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1319,  0.0136, -0.0862, -0.0593, -0.2027,  0.1671, -0.3964,\n",
       "            0.0915,  0.0247, -0.1300],\n",
       "          [-0.0866,  0.6776, -0.6119,  0.4322, -0.0576, -1.1274,  0.0776,\n",
       "            0.5618,  0.3047,  0.6047],\n",
       "          [-0.0753, -0.2872, -0.1330,  0.3314,  0.3718,  0.3554,  0.0554,\n",
       "            0.0717, -0.3402,  0.1866]]], grad_fn=<ThMulBackward>),\n",
       " torch.Size([1, 3, 10]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2c = H * b.unsqueeze(2)\n",
    "q2c, q2c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 10]), torch.Size([1, 3, 10]), torch.Size([1, 3, 10]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.size(), c2q.size(), q2c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_G = 8*d\n",
    "beta = nn.Linear(4*2*d, d_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 40])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = beta(torch.cat([H, c2q, H*c2q, H*q2c], dim=-1))\n",
    "G.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_layer = nn.LSTM(input_size=d_G,\n",
    "                         hidden_size=d,\n",
    "                         num_layers=3,\n",
    "                         batch_first=True,\n",
    "                         bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M, _ = modeling_layer(G)\n",
    "M.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "\n",
    "application-specific: QA task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 10]), torch.Size([1, 3, 40]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.size(), G.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_linear = nn.Linear(10*d, 1, bias=False)\n",
    "output_lstm = nn.LSTM(input_size=2*d,\n",
    "                      hidden_size=d,\n",
    "                      num_layers=3,\n",
    "                      batch_first=True,\n",
    "                      bidirectional=True)\n",
    "end_linear = nn.Linear(10*d, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1_cat = torch.cat([G, M], dim=-1)\n",
    "p1 = torch.log_softmax(start_linear(p1_cat).squeeze(2), dim=-1)\n",
    "p1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2, _ = p2_lstm(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2_cat = torch.cat([G, M2], dim=-1)\n",
    "p2 = torch.log_softmax(end_linear(p2_cat).squeeze(2), dim=-1)\n",
    "p2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1541, grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_f1 = nn.NLLLoss()\n",
    "loss_f2 = nn.NLLLoss()\n",
    "loss_f1(p1, torch.LongTensor([0])) + loss_f2(p2, torch.LongTensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
