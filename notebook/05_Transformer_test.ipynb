{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/'.join(os.getcwd().split('/')[:-1]+['paper_code/TRANSFORMER']))\n",
    "# package load\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import Transformer\n",
    "from train import cal_performance, get_pos\n",
    "from torchtext.data import Field, Iterator\n",
    "from torchtext import datasets\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from schoptim import ScheduledOptim\n",
    "from lbs import LabelSmoothing\n",
    "from utils import get_padding_mask\n",
    "from trans_dataloader import TranslateDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "SOS = '<s>'\n",
    "EOS = '</s>'\n",
    "SRC = Field(tokenize=tokenize_de, lower=True, batch_first=True)\n",
    "TRG = Field(tokenize=tokenize_en, init_token=SOS, eos_token=EOS, lower=True, batch_first=True)\n",
    "\n",
    "MAX_LEN = 50\n",
    "train, valid, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(SRC, TRG), \n",
    "        root='../data/', filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "        len(vars(x)['trg']) <= MAX_LEN)\n",
    "MIN_FREQ = 2\n",
    "SRC.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "TRG.build_vocab(train.trg, min_freq=MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, test_loader = Iterator.splits(datasets=(train, valid, test), \n",
    "    batch_sizes=(16, 16, 16), repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in train_loader:\n",
    "     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_data - train: 196546 valid: 992 test: 1305\n",
      "len_loader - train: 12285 valid: 62 test: 82\n"
     ]
    }
   ],
   "source": [
    "print('len_data - train: {} valid: {} test: {}'.format(len(train), len(valid), len(test)))\n",
    "print('len_loader - train: {} valid: {} test: {}'.format(len(train_loader), len(valid_loader), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = None\n",
    "# Parameters\n",
    "N_LAYER = 6\n",
    "N_HEAD = 8\n",
    "D_K = 64\n",
    "D_V = 64\n",
    "D_MODEL = D_K * N_HEAD\n",
    "D_F = D_MODEL * 4\n",
    "SAVE_PATH = '../paper_code/TRANSFORMER/model/transformer.chkpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(enc_vocab_len=len(SRC.vocab.stoi),\n",
    "                    enc_max_seq_len=MAX_LEN, \n",
    "                    dec_vocab_len=len(TRG.vocab.stoi), \n",
    "                    dec_max_seq_len=MAX_LEN+2, \n",
    "                    n_layer=N_LAYER, \n",
    "                    n_head=N_HEAD, \n",
    "                    d_model=D_MODEL, \n",
    "                    d_k=D_K,\n",
    "                    d_v=D_V,\n",
    "                    d_f=D_F, \n",
    "                    pad_idx=SRC.vocab.stoi['<pad>'],\n",
    "                    drop_rate=0.1, \n",
    "                    use_conv=False, \n",
    "                    return_attn=True, \n",
    "                    linear_weight_share=True, \n",
    "                    embed_weight_share=False).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_to_tensor(sent, vocab, unk='<unk>'):\n",
    "    sent = [vocab.get(x) if vocab.get(x) is not None else vocab.get(unk) for x in sent]\n",
    "    return torch.LongTensor([sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ex = np.random.choice(test.examples)\n",
    "src_sent, trg_sent = test_ex.src, test_ex.trg\n",
    "src = process_to_tensor(src_sent, vocab=SRC.vocab.stoi)\n",
    "src_pos = get_pos(src)\n",
    "trg = process_to_tensor(['<s>'], vocab=TRG.vocab.stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory, enc_attns = model.encoder(src, src_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, dec_attns, dec_enc_attns = model.decoder(trg, trg_pos, src, memory)\n",
    "output = model.projection(output[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg = torch.cat((trg[0], output.max(1)[1])).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_pos = get_pos(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 2, 2]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(model, src, src_pos, trg, max_len=100, eos_idx=3):\n",
    "    trg_pos = get_pos(trg)\n",
    "    memory, enc_attns = model.encoder(src, src_pos)\n",
    "    for i in range(max_len):\n",
    "        output, dec_attns, dec_enc_attns = model.decoder(trg, trg_pos, src, memory)\n",
    "        output = model.projection(output[:, -1])\n",
    "        trg = torch.cat((trg[0], output.max(1)[1])).unsqueeze(0)\n",
    "        if output.max(1)[1].item() == eos_idx:\n",
    "            break\n",
    "        trg_pos = get_pos(trg)\n",
    "    return trg.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = decode(model, src, src_pos, trg, max_len=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "o, attns = model(src, src_pos, trg, get_pos(trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([24.5936], grad_fn=<MaxBackward0>), tensor([2]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    src, trg = batch.src, batch.trg\n",
    "    src_pos, trg_pos = map(get_pos, [src, trg])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.encoder.pos_layer(src_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = model.encoder.embed_layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 42, 512]), torch.Size([16, 42, 512]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(), b.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# optimizer = ScheduledOptim(optim.Adam(filter(lambda x: x.requires_grad, model.parameters()),\n",
    "#                        betas=(0.9, 0.98), eps=1e-09), \n",
    "#                        D_MODEL, \n",
    "#                        4000)\n",
    "# loss_function = LabelSmoothing(trg_vocab_size=len(TRG.vocab.stoi), \n",
    "#                                pad_idx=TRG.vocab.stoi['<pad>'], \n",
    "#                                eps=0.1)\n",
    "\n",
    "# model = model.to(DEVICE)\n",
    "# model.train()\n",
    "# loss_per_step = 0\n",
    "# total_words = 0\n",
    "# correct_words = 0\n",
    "\n",
    "# start_time = time.time()\n",
    "# for i, batch in enumerate(train_loader):\n",
    "#     src_pos, trg_pos = map(get_pos, [batch.src, batch.trg])\n",
    "#     src, src_pos, trg, trg_pos = map(lambda x: x.to(DEVICE), [batch.src, src_pos, batch.trg, trg_pos])\n",
    "#     model.zero_grad()\n",
    "#     # forward\n",
    "#     output = model(enc=src, enc_pos=src_pos, dec=trg, dec_pos=trg_pos)\n",
    "#     # loss and backward\n",
    "#     pred = output.to('cpu')\n",
    "#     target = trg.detach().to('cpu')\n",
    "#     loss, n_correct = cal_performance(pred, target, loss_function, pad_idx=model.pad_idx)\n",
    "#     loss.backward()        \n",
    "#     # update parameters\n",
    "#     optimizer.step_and_update_lr()\n",
    "\n",
    "#     # eval\n",
    "#     n_words = target.view(-1).ne(model.pad_idx).sum().item()\n",
    "#     total_words += n_words\n",
    "#     correct_words += n_correct\n",
    "#     loss_per_step += loss.item()\n",
    "\n",
    "#     end_time = time.time()\n",
    "#     total_time = end_time-start_time\n",
    "#     print(' > [{}/{}] loss_per_batch: {:.4f} time: {:.1f} s'.format(i, len(train_loader), \n",
    "#                                                                      loss.item()/n_words, total_time))\n",
    "#     start_time = time.time()\n",
    "\n",
    "# accuracy = correct_words / total_words\n",
    "# loss_per_step = loss_per_step / total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://nlp.seas.harvard.edu/2018/04/03/attention.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda settings\n",
    "DEVICE = None\n",
    "# TRAIN_PATH = '../data/translation/de_en_small.txt'\n",
    "# VALID_PATH = '../data/translation/de_en_small_valid.txt'\n",
    "TRAIN_PATH = '../data/translation/en_fa2.train'\n",
    "VALID_PATH = '../data/translation/en_fa2.valid'\n",
    "TEST_PATH = '../data/translation/en_fa2.test'\n",
    "EXTS = 'src-trg'\n",
    "SOS = '<s>'\n",
    "EOS = '</s>'\n",
    "STEP = 10\n",
    "BATCH = 3\n",
    "# Create Dataset\n",
    "train = TranslateDataset(path=TRAIN_PATH, exts=EXTS, sos=SOS, eos=EOS)\n",
    "SRC_VOCAB = train.src_vocab\n",
    "TRG_VOCAB = train.trg_vocab\n",
    "valid = TranslateDataset(path=VALID_PATH, sos=SOS, eos=EOS, vocab=[('src', SRC_VOCAB), ('trg', TRG_VOCAB)])\n",
    "test = TranslateDataset(path=TEST_PATH, sos=SOS, eos=EOS, vocab=[('src', SRC_VOCAB), ('trg', TRG_VOCAB)])\n",
    "# Parameters\n",
    "N_LAYER = 6\n",
    "N_HEAD = 8\n",
    "D_K = 64\n",
    "D_V = 64\n",
    "D_MODEL = D_K * N_HEAD\n",
    "D_F = D_MODEL * 4\n",
    "SAVE_PATH = '../paper_code/TRANSFORMER/model/enfa2.chkpt'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
